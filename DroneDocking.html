<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    h2 {
        font-weight: 300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2HYEBBLV5B"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2HYEBBLV5B');
</script>
        <title>Drone Docking</title>
        <meta property="og:title" content="Factored 3D" />
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">Deep Reinforcement Learning for Sim2Real Policy Transfer in VTOL-UAVs Offshore Docking Operations</span>
    </center>

    <br><br>
      <table align=center width=900px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://phoenixrider12.github.io/">Ali Mohamed Ali<sup>1</sup></a></span>
        </center>
        </td>

        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://vatsuak.github.io/">Aryaman Gupta<sup>2</sup></a></span>
        </center>
        </td>

        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://smlbansal.github.io/">Hashim A.Hashim<sup>1</sup></a></span>
        </center>
        </td>
     </tr>
    </table>

    <br>
    <table align=center width=700px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:15px"><sup>1</sup>Carleton University <sup>2</sup>Indian Institute of Technology (BHU), Varanasi</span>
        </center>
        </td>
     </tr>
    </table>
    <br><br>
  <table align=center>

          <hr>
    <center><h1>Abstract</h1></center>

            <br>
            This paper proposes a novel Reinforcement Learning (RL) approach for sim-to-real policy transfer of Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL-UAV). The proposed approach is designed for VTOL-UAV landing on offshore docking stations in maritime operations. VTOL-UAVs in maritime operations encounter limitations in their operational range, primarily stemming from constraints imposed by their battery capacity. The concept of autonomous landing on a charging platform presents an intriguing prospect for mitigating these limitations by facilitating battery charging and data transfer. However, current Deep Reinforcement Learning (DRL) methods exhibit drawbacks, including lengthy training times, and modest success rates. In this paper, we tackle these concerns comprehensively by decomposing the landing procedure into a sequence of more manageable but analogous tasks in terms of an approach phase and a landing phase. The proposed architecture utilizes a model-based control scheme for the approach phase, where the VTOL-UAV is approaching the offshore docking station. In the Landing phase, DRL agents were trained offline to learn the optimal policy to dock on the offshore station. The Joint North Sea Wave Project (JONSWAP) spectrum model has been employed to create a wave model for each episode, enhancing policy generalization for sim2real transfer. A set of DRL algorithms have been tested through numerical simulations including value-based agents and policy-based agents such as Deep Q Networks (DQN) and Proximal Policy Optimization (PPO) respectively. The numerical experiments show that the PPO agent can learn complicated and efficient policies to land in uncertain environments, which in turn enhances the likelihood of successful sim-to-real transfer.
            <br><br>
          <hr>
         <!-- <table align=center width=550px> -->
            <table align=center width=650>
             <center><h1>Paper/Code</h1></center>
                <tr>
                  <td><a href="https://www.sciencedirect.com/science/article/pii/S1568494624006173?ref=pdf_download&fr=RR-2&rr=89f67841391f91cd"><img style="height:280px" src="papers/drone_docking/drone_docking_paper_review.png"/></a></td>
                  <td><span style="font-size:14pt">Ali, Gupta, Hashim<br><br>
                    Deep Reinforcement Learning for sim-to-real policy transfer of VTOL-UAVs offshore docking operations
                    </td>
              </tr>
            </table>
          <br>

          <table align=center width=300px>
              <tr>
                  <td><span style="font-size:14pt"><center>
                      <a href="https://www.sciencedirect.com/science/article/pii/S1568494624006173?ref=pdf_download&fr=RR-2&rr=89f67841391f91cd">[pdf]</a>
                    </center></td>

                  <td><span style="font-size:14pt"><center>
                      <a href="papers/drone_docking/">[Bibtex]</a>
                    </center></td>
                
                    <td><span style="font-size:14pt"><center>
                        <a href="https://github.com/phoenixrider12/drone_docking">[Code]</a>
                      </center></td>
              </tr>
            </table>
              <br>

                <hr>

          <center><h1>Results</h1></center>
          <table align=center width=1000px>
              <tr>
                  <td width=1000px>
                    <center>
                        <a href="papers/drone_docking/results1.png"><img src = "papers/drone_docking/results1.png" width="1000px"></img></href></a><br>
                  </center>
                  </td>
              </tr>
                  <td width=1000px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Fig.</span> <b>(a)</b> compares the number of time steps needed to land for all the agents. <b>(b)</b> illustrates the actor and critic loss moving average value of the PPO agent, while
                            <b>(c)</b> shows the moving average loss value of the DQNs agents. <b>(d),(e)</b> depict the moving average of the reward of DQNs and PPO agents respectively. Finally,
                            <b>(f)</b> compares the final height achieved by DQN and PPO agents. The shaded parts in all figures represent the standard deviation of the moving average.</i>
                  </center>
                  </td>
              </tr>
              <tr>
                <td width=500px>
                  <center>
                      <a href="papers/drone_docking/results2.png"><img src = "papers/drone_docking/results2.png" width="500px"></img></href></a><br>
                </center>
                </td>
            </tr>
                <td width=500px>
                  <center>
                      <span style="font-size:14px"><i> <span style="font-weight:bold">Fig.</span> Comparison between the final impact velocity of the VTOL-UAV in the case
                        of PPO and DQN agents.</i>
                </center>
                </td>
            </tr>

            <tr>
                <td width=800px>
                  <center>
                      <a href="papers/drone_docking/results3.png"><img src = "papers/drone_docking/results3.png" width="800px"></img></href></a><br>
                </center>
            </td>
            </tr>
            <td width=800px>
                <center>
                    <span style="font-size:14px"><i> <span style="font-weight:bold">Fig.</span> Evaluation of the trained agents. </i>
              </center>
              </td>
          </tr>

          </table>
          <br>
           <hr>
            <br>
            <table align=center width=1100px>
                <tr>
                    <td>
                      <left>
                This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
