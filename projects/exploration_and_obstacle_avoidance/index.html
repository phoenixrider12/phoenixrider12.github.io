<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    h2 {
        font-weight: 300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>Aryaman Gupta</title>
        <meta property="og:title" content="Factored 3D" />
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px"><u>Multi-Agent Exploration & Dynamic Obstacle Avoidance</u></span>
    </center>

    <br><br>

    <table align=center width=1000px>
        <tr>
                <!-- <center> -->
                  <!-- <a href=''><img class="round" style="width: 400;" src="mapping_ss.png"/></a> -->
                <!-- </center> -->
                <center>
                  <a href=''><img class="round" style="width: 700;" src="nav_test_ss.png"/></a>
                </center>
      </tr>
  </table>
            <br><br>

            <!-- <br> -->
            In this project, we are trying to develop a Multi-Robot Mapping pipeline that can be used for manual/autonomous mapping of unknown terrains with multiple robots without any prior information about the environment. Also, once the map is prepared, we are trying to incorporate dynamic environment changes in our generated occupancy grid from knowledge gained from camera sensors.
            <br><br>

          <!-- <br> -->

          <table align=center width=180px>
              <tr>
                  <td><span style="font-size:14pt">
                      <a href="https://github.com/phoenixrider12/Multi-VOLTA-Exploration-and-Dynamic-Map-Updates">[Code]</a>
                    </td>

                    <td><span style="font-size:14pt">
                      <a href="https://docs.google.com/presentation/d/1aI4XAEJ03-eVSFvvPp1vc2dhd3e40BZHbnoN6kscu6A/edit?usp=sharing">[Slides]</a>
                    </td>
              </tr>
            </table>
              <br>

                <hr>

         <center><h1>Manual Multi-Robot Mapping</h1></center>
            <table align=center width=1000px>
                <tr>
                        <center>
                          <a href=''><img class="round" style="width: 500;" src="map_merge.gif"/></a>
                          <figcaption><i>Vox-Bot CAD design</i></figcaption>
                        </center>
              </tr>
          </table>
        <br><br>
        For manual multi-robot mapping, we are using standard LIDAR based SLAM Gmapping for individual robot to prepare individual maps and then merging them to produce a global map. For merging, a feature matching algorithm is used which detects overlapping features in individual maps and combines them with/without knowing the initial position of any robot. More details can be found <a href="http://wiki.ros.org/multirobot_map_merge">here</a>.
        <br><br>

          <table align=center>
            <tr>
                <td width=1000>
                  <center>
                    <!-- METHOD VIDEO HERE -->
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/nefMJ8caYpQ?si=6q2gA_vGh-BYTdrs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>                </td>
            </tr>
          </table>
          <br>
          <hr>

          <center><h1>Multi-Robot Exploration</h1></center>

          <p>
            Exploration is always preferred while mapping because the robots can autonomously generate a map without any human effort. The classical way of exploration is to get frontier points on edges of generated occupancy grid and forwarding those points as goal to the robot so that it can traverse to the point and explore that area. There are several open-source ROS packages available for this approach, like <a href="http://wiki.ros.org/explore_lite">explore_lite</a> and <a href="http://wiki.ros.org/frontier_exploration">frontier exploration</a>.
          </p>

          <p>
            In our approach, we are using <b>RRT (Rapidly Exploring Random Trees) Exploration</b>. Here, modified RRT algorithm is used for detecting frontier points, which has proven to be much faster than standard exploration. In this algorithm, we run two different ROS nodes for exploration:
            <ul>
            <li>Global Frontier Detector: Find frontier points in global occupancy grid.</li>
            <li>Local Frontier Detector : Find frontier points in each robot's local occupancy grid.(local node for each robot)</li>
            </ul>
          </p>

          <table align=center width=1000px>
              <tr>
                      <center>
                        <a href=''><img class="round" style="width: 600;" src="rrt_exploration.gif"/></a>
                        <figcaption><i>Complete Pipeline of our solution</i></figcaption>
                      </center>
            </tr>
        </table>

        <p>
          This algorithm runs until the loop closure condition in global map is not satisfied. Here, we assume that the surface of the environment always forms a closed loop and the algorithm stops once it canâ€™t find any open frontiers in the current map, denoting that all the traversable parts of the terrain are mapped, and no more global frontiers are found. More details about this ROS package can be found on <a href="http://wiki.ros.org/rrt_exploration">Wiki</a>.
        </p>
    <hr>
    
    <center><h1>Dynamic Obstacle Avoidance</h1></center>
    <p>
    Ground robots are very commonly used in warehouses and factories where the environment is never static and it keeps changing. Hence, we want to create a system which can dynamically change the global costmap whenever there is any change in the environment.
    </p>
    <p>
    For this purpose, we are creating an <b>Object Detection and Map Update</b> pipeline.
    </p>

    <h2><b>3D Object Detection</h2></b>

    <p>
    Here we are using 3D Object Detection instead of standard 2D object detection because for accurately updating costmap, we need object's position as well as an estimate of its dimensions in the real world, and 2D object detection can't provide us that information because it returns a 2D bounding box, whereas 3D object detection can provide that information because it returns a 3D bounding box in camera'a view frame.
    </p>

    <p>
    For our purpose, we are using Mediapipe's <a href="https://google.github.io/mediapipe/solutions/objectron.html#camera-coordinate">Objectron</a> module. It is an opensource module which can detect objects like chairs, shoes, coffee mugs and cameras.
    </p>

    <table align=center width=1000px>
      <tr>
              <center>
                <a href=''><img class="round" style="width: 700;" src="objectron.png"/></a>
                <figcaption><i>Complete Pipeline of our solution</i></figcaption>
              </center>
    </tr>

    <p>
      After getting coordinates of all 9 points in camera view frame, we transform them into real world using <a href="https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/lookat-function">Look-At Transformation</a> technique. Since we can't transform a point to its actual real world coordinate but instead to a 3D line in real world, we compute multiple such lines using multiple cameras and then use gradient descent optimization algorithm to extract the actual coordinates of each point. Then from the real world coordinates of all 9 points, we compute its center's coordinates and its dimensions.
    </p>

    <h2><b>Map Update</h2></b>

    For performing map updates, we have added a new layer to the global costmap as a plugin. That plugin receives data from objectron and updates the cost of object's new location as well as its previous location. Here is a demo video:
    <br>
    <table align=center>
      <tr>
          <td width=1000>
            <center>
              <!-- METHOD VIDEO HERE -->
              <iframe width="560" height="315" src="https://www.youtube.com/embed/QN1Fg9xuopc?si=2zEWUFm12AyoZu3O" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>      </tr>
    </table>
    <br>
    Here is a demo of VOLTA's navigation test while performing map updates:
    <table align=center>
      <tr>
          <td width=1000>
            <center>
              <!-- METHOD VIDEO HERE -->
              <iframe width="560" height="315" src="https://www.youtube.com/embed/PSlzpGhmcgs?si=NTIbzNc4VfrLkIKb" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>    </table>

</table>

    <br>
    <hr>

        <table align=center width=1100px>
        <tr>
        <td>
            <left>
                This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
